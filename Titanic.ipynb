# TITANIC EDA, FEATURE ENGINEERING & ML EXPERIMENTS

# Импортирование необходимых библиотек для анализа и визуализации
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Загрузка данных
df = pd.read_csv("Titanic.csv")
print("Размерность набора данных:", df.shape)  # Печать размеров данных
df.head()  # Просмотр первых 5 строк для быстрого понимания структуры данных

# Этап 1: Операции с данными

# Проверка на пропущенные значения и общая информация о типах данных
df.info()  # Информация о данных, включая количество ненулевых значений в каждом столбце
df.isna().sum()  # Проверка количества пропущенных значений в каждом столбце

# Визуализация распределения числовых признаков, таких как возраст и стоимость билета
fig, axs = plt.subplots(1, 2, figsize=(12, 5))
sns.histplot(df['Age'], kde=True, ax=axs[0]).set_title('Распределение возраста')
sns.histplot(df['Fare'], kde=True, ax=axs[1]).set_title('Распределение стоимости билета')
plt.tight_layout()
plt.show()

# Построение графика для категориальных переменных (пол и класс пассажира)
sns.countplot(x='Sex', hue='Survived', data=df)
plt.title("Выживаемость по полу")
plt.show()

sns.countplot(x='Pclass', hue='Survived', data=df)
plt.title("Выживаемость по классу пассажира")
plt.show()

# Построение корреляционной матрицы для числовых признаков и категориальных данных
df_corr = df.copy()
df_corr['Sex'] = df_corr['Sex'].map({'male': 0, 'female': 1})  # Преобразование пола в числовой формат
df_corr['Embarked'] = df_corr['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})  # Преобразование порта посадки
sns.heatmap(df_corr.corr(), annot=True, cmap='coolwarm')
plt.title("Корреляционная матрица признаков")
plt.show()

# Этап 2: Инженерия признаков

# Извлечение титула из имени пассажира для дополнительной информации
df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)  # Извлечение титула
df['Title'] = df['Title'].replace(['Mlle', 'Ms'], 'Miss')  # Объединяем титулы
df['Title'] = df['Title'].replace(['Mme'], 'Mrs')  # Объединяем титулы
df['Title'] = df['Title'].replace(['Dr', 'Major', 'Col', 'Sir', 'Lady', 'Capt', 'Don', 'Jonkheer', 'Rev', 'Countess'], 'Rare')  # Редкие титулы

# Заполнение пропущенных значений в важных признаках
df['Age'] = df['Age'].fillna(df['Age'].median())  # Возраст заполняем медианным значением
df['Fare'] = df['Fare'].fillna(df['Fare'].median())  # Стоимость билета заполняем медианным значением
df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])  # Порт посадки заполняем самым частым значением

# Кодирование категориальных признаков в числовой формат для обучения моделей
df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})  # Кодирование пола
df['Embarked'] = df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})  # Кодирование порта посадки
df['Title'] = df['Title'].map({
    'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Rare': 4
}).fillna(4)  # Кодирование титулов

# Этап 3: Построение модели для оценки важности признаков

from sklearn.ensemble import RandomForestClassifier

# Отбор признаков для модели
features = ['Pclass', 'Sex', 'Age', 'Fare', 'SibSp', 'Parch', 'Embarked', 'Title']
X = df[features]
y = df['Survived']

# Обучение модели случайного леса для оценки важности признаков
model = RandomForestClassifier(random_state=42)
model.fit(X, y)
importances = model.feature_importances_

# Визуализация важности признаков
sns.barplot(x=importances, y=features)
plt.title("Важность признаков")
plt.show()

# Этап 4: Оценка нескольких моделей с использованием кросс-валидации

# Импортирование необходимых библиотек для различных моделей
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.wrappers.scikit_learn import KerasClassifier

# Создание словаря моделей для сравнения
models = {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree": DecisionTreeClassifier(),
    "XGBoost": XGBClassifier(eval_metric='logloss', use_label_encoder=False)
}

# Оценка моделей с использованием кросс-валидации
for name, model in models.items():
    scores = cross_val_score(model, X, y, cv=5)
    print(f"{name} - Средняя точность (CV): {scores.mean():.4f} (+/- {scores.std():.4f})")

# Создание нейронной сети для классификации
def create_nn_model():
    model = Sequential()
    model.add(Dense(16, input_dim=X.shape[1], activation='relu'))  # Входной слой
    model.add(Dense(8, activation='relu'))  # Скрытый слой
    model.add(Dense(1, activation='sigmoid'))  # Выходной слой для бинарной классификации
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Компиляция модели
    return model

# Оценка модели нейронной сети с кросс-валидацией
nn_model = KerasClassifier(build_fn=create_nn_model, epochs=50, batch_size=5, verbose=0)
nn_scores = cross_val_score(nn_model, X, y, cv=5)
print(f"Нейронная сеть - Средняя точность (CV): {nn_scores.mean():.4f} (+/- {nn_scores.std():.4f})")

# Итоговые выводы

# После выполнения кросс-валидации для нескольких моделей, можно отметить, что:
# - Модели XGBoost и нейронная сеть показывают лучшие результаты по точности на этом наборе данных.
# - Важность признаков показывает, что такие признаки как пол, класс пассажира и возраст имеют наибольшее влияние на вероятность выживания.

# Рекомендуется использовать модель XGBoost для дальнейшей оптимизации и прогнозирования. Также стоит поработать с гиперпараметрами для улучшения результатов нейронной сети.
